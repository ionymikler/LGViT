{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "import os, sys\n",
    "repo_path = os.path.abspath(\"..\")  # Assuming the notebook is inside the utils folder\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "\n",
    "# local\n",
    "from examples.lgvit_utils import (\n",
    "    ModelArguments,\n",
    "    DataTrainingArguments,\n",
    ")\n",
    "\n",
    "from models.deit_highway import DeiTImageProcessor, DeiTConfig, DeiTHighwayForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the bash running scripts\n",
    "BACKBONE = \"ViT\" # ViT, DeiT\n",
    "EXIT_STRATEGY=\"confidence\" # entropy, confidence, patience, patient_and_confident\n",
    "HIGHWAY_TYPE=\"LGViT\" # linear, LGViT, vit, self_attention, conv_normal\n",
    "PAPER_NAME=\"LGViT\"  # base, SDN, PABEE, PCEE, BERxiT, ViT-EE, LGViT\n",
    "TRAIN_STRATEGY=\"no_train\" # no_train, normal, weighted, alternating, distillation, alternating_weighted\n",
    "\n",
    "\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "args = [\n",
    "\"--run_name\" ,f\"${BACKBONE}_${EXIT_STRATEGY}_${HIGHWAY_TYPE}_${TRAIN_STRATEGY}_${PAPER_NAME}\",\n",
    "\"--image_processor_name\" ,\"facebook/deit-base-distilled-patch16-224\",\n",
    "\"--config_name\" ,\"facebook/deit-base-distilled-patch16-224\",\n",
    "\"--model_name_or_path\" ,\"/home/iony/DTU/f24/thesis/code/lgvit/LGViT-ViT-Cifar100\",\n",
    "\"--dataset_name\" ,\"uoft-cs/cifar100\",\n",
    "\"--output_dir\" ,\"../outputs/DeiT-base/uoft-cs/cifar100/LGViT/confidence/\",\n",
    "\"--remove_unused_columns\" ,\"False\",\n",
    "\"--backbone\" ,\"ViT\", # ViT, DeiT\n",
    "\"--exit_strategy\" ,\"confidence\",\n",
    "\"--do_train\" ,\"False\",\n",
    "\"--do_eval\", \"True\",\n",
    "\"--per_device_eval_batch_size\" ,\"1\",\n",
    "\"--seed\" ,\"777\",\n",
    "\"--report_to\" ,\"wandb\",\n",
    "\"--use_auth_token\" ,\"False\",\n",
    "\"--ignore_mismatched_sizes\" ,\"False\",\n",
    "]\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(args)\n",
    "\n",
    "task_arg = datasets.ImageClassification(image_column='img', label_column='fine_label')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset, image_loader preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = datasets.load_dataset(\n",
    "    path=data_args.dataset_name,\n",
    "    name=data_args.dataset_config_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    task=task_arg, #Deprecated in 2.13.0\n",
    "    token=True if model_args.use_auth_token else None,\n",
    "    # use_auth_token=True if model_args.use_auth_token else None,\n",
    "    # ignore_verifications=True,\n",
    ")\n",
    "\n",
    "image_processor = DeiTImageProcessor.from_pretrained(\n",
    "    model_args.image_processor_name or model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    ")\n",
    "\n",
    "# attaching the data transformation to the dataset\n",
    "\n",
    "\n",
    "size = 224\n",
    "_train_transforms = Compose(\n",
    "    [\n",
    "        RandomResizedCrop(size),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "def train_transforms(example_batch:dict):\n",
    "    \"\"\"Apply _train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        _train_transforms(pil_img.convert(\"RGB\")) for pil_img in example_batch[\"image\"]\n",
    "    ]\n",
    "    del example_batch[\"image\"]\n",
    "\n",
    "    return example_batch\n",
    "\n",
    "dataset_dict[\"train\"].set_transform(train_transforms)\n",
    "\n",
    "# Prepare label mappings.\n",
    "# We'll include these in the model's config to get human readable labels in the Inference API.\n",
    "labels = dataset_dict[\"train\"].features[\"labels\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only eval case\n",
    "config = DeiTConfig.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    finetuning_task=\"image-classification\",\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    backbone=model_args.backbone,\n",
    "    threshold=model_args.threshold,\n",
    "    exit_strategy=model_args.exit_strategy,\n",
    "    # train_strategy=model_args.train_strategy,\n",
    "    # num_early_exits=model_args.num_early_exits,\n",
    "    # position_exits=model_args.position_exits,\n",
    "    # highway_type=model_args.highway_type,\n",
    "    # loss_coefficient=model_args.loss_coefficient,\n",
    "    # homo_loss_coefficient=model_args.homo_loss_coefficient,\n",
    "    # hete_loss_coefficient=model_args.hete_loss_coefficient,\n",
    "    # feature_loss_coefficient=model_args.feature_loss_coefficient,\n",
    "    # output_hidden_states=model_args.output_hidden_states,\n",
    "    # use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "\n",
    "\n",
    "total_optimization_steps = int(len(dataset_dict['train']) // training_args.per_device_train_batch_size * training_args.num_train_epochs)\n",
    "config.total_optimization_steps = total_optimization_steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeiTHighwayForImageClassification.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    train_highway=True,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    # use_auth_token=True if model_args.use_auth_token else None,\n",
    "    ignore_mismatched_sizes=model_args.ignore_mismatched_sizes,\n",
    ")\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
